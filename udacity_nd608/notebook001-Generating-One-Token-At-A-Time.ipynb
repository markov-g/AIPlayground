{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c869cb7c6f77117f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:31:09.386541Z",
     "start_time": "2024-02-17T22:31:04.320193Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f26328faa809a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1. Load a tokenizer and a model\n",
    "\n",
    "First we load a tokenizer and a model from HuggingFace's transformers library. A tokenizer is a function that splits a string into a list of numbers that the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e53ea9e02d98a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:34:24.487080Z",
     "start_time": "2024-02-17T22:33:16.238829Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697a768c70e347d8b07ca4b16530370a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1345c9ca0236484d934240eb96f97ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85028b759b314c769d352ea01c27328b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c3648e0fec4c0dad889e2d7bf32a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151638b0f5814cddafcc0bfe19ce644a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703687d4415949b68a4371575c44bc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a pretrained model and a tokenizer using HuggingFace\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Create a partial sentence and tokenize it\n",
    "text = \"The best place to learn about generative AI online is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df6caa02e6fef3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:36:31.610482Z",
     "start_time": "2024-02-17T22:36:31.604950Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 464, 1266, 1295,  284, 2193,  546, 1152,  876, 9552, 2691,  318]])\n"
     ]
    }
   ],
   "source": [
    "# Show tokenized input as numbers\n",
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc8757bed4d15c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2. Examine the tokenization\n",
    "\n",
    "Let's explore what these tokens mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc992ac04039234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:40:25.949102Z",
     "start_time": "2024-02-17T22:40:24.372997Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79467/3429066191.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(464)</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1266)</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1295)</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(284)</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(2193)</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(546)</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(1152)</td>\n",
       "      <td>gener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(876)</td>\n",
       "      <td>ative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(9552)</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(2691)</td>\n",
       "      <td>online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tensor(318)</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token ID    Token\n",
       "0    tensor(464)      The\n",
       "1   tensor(1266)     best\n",
       "2   tensor(1295)    place\n",
       "3    tensor(284)       to\n",
       "4   tensor(2193)    learn\n",
       "5    tensor(546)    about\n",
       "6   tensor(1152)    gener\n",
       "7    tensor(876)    ative\n",
       "8   tensor(9552)       AI\n",
       "9   tensor(2691)   online\n",
       "10   tensor(318)       is"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how the sentence is tokenized\n",
    "import pandas as pd\n",
    "\n",
    "def show_tokenization(inputs):\n",
    "    df = pd.DataFrame(\n",
    "        [ (id, tokenizer.decode(id)) for id in inputs[\"input_ids\"][0]],\n",
    "        columns=[\"Token ID\", \"Token\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "show_tokenization(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456c3ac265c10d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 3. Calculate the probability of the next token\n",
    "\n",
    "Now let's use PyTorch to calculate the probability of the next token given the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e357878d7d21c24e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:46:28.852909Z",
     "start_time": "2024-02-17T22:46:28.789790Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9b7d8cab29ee565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:46:56.178826Z",
     "start_time": "2024-02-17T22:46:55.616447Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Token</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>at</td>\n",
       "      <td>0.099570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>the</td>\n",
       "      <td>0.095797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>by</td>\n",
       "      <td>0.079331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>832</td>\n",
       "      <td>through</td>\n",
       "      <td>0.061990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>in</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>here</td>\n",
       "      <td>0.040486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>with</td>\n",
       "      <td>0.036844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>on</td>\n",
       "      <td>0.022664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>284</td>\n",
       "      <td>to</td>\n",
       "      <td>0.019920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>3012</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.018675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>from</td>\n",
       "      <td>0.014524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>2884</td>\n",
       "      <td>via</td>\n",
       "      <td>0.011536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>a</td>\n",
       "      <td>0.009482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>The</td>\n",
       "      <td>0.007479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>674</td>\n",
       "      <td>our</td>\n",
       "      <td>0.007447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Token  Probability\n",
       "379    379        at     0.099570\n",
       "262    262       the     0.095797\n",
       "416    416        by     0.079331\n",
       "832    832   through     0.061990\n",
       "287    287        in     0.059600\n",
       "994    994      here     0.040486\n",
       "351    351      with     0.036844\n",
       "319    319        on     0.022664\n",
       "284    284        to     0.019920\n",
       "3012  3012    Google     0.018675\n",
       "422    422      from     0.014524\n",
       "2884  2884       via     0.011536\n",
       "257    257         a     0.009482\n",
       "383    383       The     0.007479\n",
       "674    674       our     0.007447"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_next_token_choices(probabilities, top_n=15):    \n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            (id, tokenizer.decode(id), p.item()) for id, p in enumerate(probabilities) if p.item()\n",
    "        ],\n",
    "        columns=[\"Id\", \"Token\", \"Probability\"]\n",
    "    ).sort_values(\"Probability\", ascending=False).head(top_n)\n",
    "    return df\n",
    "\n",
    "show_next_token_choices(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de198e9d0059ee1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:47:59.503631Z",
     "start_time": "2024-02-17T22:47:59.495862Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token id: 379\n",
      "Next token:  at\n"
     ]
    }
   ],
   "source": [
    "# Obtain the token id for the most probable next token\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "\n",
    "print(f\"Next token id: {next_token_id}\")\n",
    "print(f\"Next token: {tokenizer.decode(next_token_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf83e89a605ef97",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4. Generate some more tokens\n",
    "\n",
    "The following cell will take `text`, show the most probable tokens to follow, and append the most likely token to text. Run the cell over and over to see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf4a2e1484a443a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:49:19.457190Z",
     "start_time": "2024-02-17T22:49:18.966531Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best place to learn about generative AI online is\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Next token probabilities:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Token</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>at</td>\n",
       "      <td>0.099570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>the</td>\n",
       "      <td>0.095797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>by</td>\n",
       "      <td>0.079331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>832</td>\n",
       "      <td>through</td>\n",
       "      <td>0.061990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>in</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>here</td>\n",
       "      <td>0.040486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>with</td>\n",
       "      <td>0.036844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>on</td>\n",
       "      <td>0.022664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>284</td>\n",
       "      <td>to</td>\n",
       "      <td>0.019920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>3012</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.018675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>from</td>\n",
       "      <td>0.014524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>2884</td>\n",
       "      <td>via</td>\n",
       "      <td>0.011536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>a</td>\n",
       "      <td>0.009482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>The</td>\n",
       "      <td>0.007479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>674</td>\n",
       "      <td>our</td>\n",
       "      <td>0.007447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     Token  Probability\n",
       "379    379        at     0.099570\n",
       "262    262       the     0.095797\n",
       "416    416        by     0.079331\n",
       "832    832   through     0.061990\n",
       "287    287        in     0.059600\n",
       "994    994      here     0.040486\n",
       "351    351      with     0.036844\n",
       "319    319        on     0.022664\n",
       "284    284        to     0.019920\n",
       "3012  3012    Google     0.018675\n",
       "422    422      from     0.014524\n",
       "2884  2884       via     0.011536\n",
       "257    257         a     0.009482\n",
       "383    383       The     0.007479\n",
       "674    674       our     0.007447"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Press ctrl + enter to run this cell again and again to see how the text is generated.\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Show the text\n",
    "print(text)\n",
    "\n",
    "# Convert to tokens\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Calculate the probabilities for the next token and show the top 5 choices\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=-1)\n",
    "\n",
    "display(Markdown(\"**Next token probabilities:**\"))\n",
    "display(show_next_token_choices(probabilities))\n",
    "\n",
    "# Choose the most likely token id and add it to the text\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "text = text + tokenizer.decode(next_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9e8b2fd71a82e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4. Use the `generate` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4dd2205cebf188c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T22:50:07.306526Z",
     "start_time": "2024-02-17T22:50:04.069728Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Once upon a time, generative models of the human brain were used to study the neural correlates of cognitive function. In the present study, we used a novel model of the human brain to investigate the neural correlates of cognitive function. We used a novel model of the human brain to investigate the neural correlates of cognitive function. We used a novel model of the human brain to investigate the neural correlates of cognitive function. We used a novel model of the human brain to investigate the neural correlates of cognitive function."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Start with some text and tokenize it\n",
    "text = \"Once upon a time, generative models\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Use the `generate` method to generate lots of text\n",
    "output = model.generate(**inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Show the generated text\n",
    "display(Markdown(tokenizer.decode(output[0])))"
   ]
  },
  {
   "cell_type": "code",
   "id": "6e5b0c37faa76b01",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
