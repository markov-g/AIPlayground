{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda6c653a0765e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T02:43:58.702960Z",
     "start_time": "2024-02-11T02:43:20.027734Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest AI technology trends for 2024 highlight significant advancements and the expanding role of AI in both professional and personal contexts. Here’s a summary of the key trends along with insights for each:\n",
      "\n",
      "1. **Multimodal AI**: This trend is about AI systems that can process and interpret multiple types of data — text, images, sound, etc. — simultaneously, much like how humans interact with the world. This represents a move towards more complex and versatile AI systems capable of understanding and operating within the rich tapestry of human sensory experience.\n",
      "\n",
      "   **Insight**: The advancement of multimodal AI could revolutionize user interfaces, making interactions with technology more intuitive and natural. This could have wide-ranging implications for accessibility, education, and entertainment, allowing for more immersive and personalized experiences.\n",
      "\n",
      "2. **Generative AI Becomes Mainstream**: Generative AI, which includes technologies capable of creating content such as text, images, and videos, is expected to become more accessible and useful to the general public. This trend suggests a democratization of AI-powered content creation tools.\n",
      "\n",
      "   **Insight**: As generative AI becomes more user-friendly, we can anticipate a surge in creative applications. This could empower individuals and small businesses to produce high-quality content with minimal resources, potentially leveling the playing field in various industries.\n",
      "\n",
      "3. **AI Integration in Daily Life**: With the widespread adoption of tools like ChatGPT by OpenAI, AI is becoming seamlessly woven into the fabric of daily life. This trend suggests a future where AI assistants are not just novelties but essential tools for managing our digital existence.\n",
      "\n",
      "   **Insight**: The integration of AI into daily life could significantly boost productivity and convenience but also raises important questions about privacy, data security, and the digital divide. Ensuring equitable access to these technologies will be crucial.\n",
      "\n",
      "4. **Generative AI in Business**: After gaining public attention, generative AI is now taking root in the business world. This indicates a transition from experimental to practical applications, with companies looking to leverage AI for innovation and efficiency.\n",
      "\n",
      "   **Insight**: The adoption of generative AI in business operations could transform industries by enhancing creativity, speeding up product development, and personalizing customer experiences. However, businesses must navigate ethical considerations and the potential impact on employment.\n",
      "\n",
      "In summary, the AI trends for 2024 suggest a year of significant technological evolution, with AI becoming more integrated into everyday life and business, fostering innovation while presenting new challenges and opportunities.\n"
     ]
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "def get_api_key():\n",
    "    _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "    return (os.getenv('OPENAI_API_KEY'), os.getenv('LANGCHAIN_API_KEY'), os.getenv('BINGSEARCH_API_SECRET'))\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "# Initialize model\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", api_key=get_api_key()[0])\n",
    "# llm = ChatOpenAI(model=\"local-model\", \n",
    "#                  api_key=get_api_key()[0], # LMStudio\n",
    "#                  openai_api_base=\"http://localhost:1234/v1\",\n",
    "#                  ) \n",
    "\n",
    "# 1. Define custom tools\n",
    "# 1. Define custom tools\n",
    "# @tool(\"internet_search\", return_direct=False)\n",
    "# def internet_search(query: str) -> str:\n",
    "#     \"\"\"Searches the internet using DuckDuckGo.\"\"\"\n",
    "#     with DDGS() as ddgs:\n",
    "#         results = [r for r in ddgs.text(query, max_results=5)]\n",
    "#         return results if results else \"No results found.\"\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using Bing Search API.\"\"\"\n",
    "    url = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": get_api_key()[2]}\n",
    "    params = {\"q\": query, \"count\": 5}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    search_results = response.json()\n",
    "\n",
    "    # Process and return the results as needed\n",
    "    results = search_results.get(\"webPages\", {}).get(\"value\", [])\n",
    "    return [result[\"snippet\"] for result in results] if results else \"No results found.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "tools = [internet_search, process_content]\n",
    "\n",
    "# 2. Agents \n",
    "# Helper function for creating agents\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "# Define agent nodes\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "# Create Agent Supervisor\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these\"\n",
    "    \" workers: {members}. Based on the user's request,\"\n",
    "    \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "    \" executing a specific task and reporting back their findings and progress. Once all tasks are complete,\"\n",
    "    \" indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}] }},\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "\n",
    "insights_research_agent = create_agent(llm, tools,\n",
    "                                       \"\"\"You are a Insight Researcher. Do step by step. \n",
    "                                       Based on the provided content first identify the list of topics,\n",
    "                                       then search internet for each topic one by one\n",
    "                                       and finally find insights for each topic one by one.\n",
    "                                       Include the insights and sources in the final response\n",
    "                                       \"\"\")\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "# Define the Agent State, Edges and Graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "# Define edges\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Run the graph\n",
    "# for s in graph.stream({\n",
    "#     \"messages\": [HumanMessage(content=\"\"\"Search for the latest AI technology trends in 2024,\n",
    "#             summarize the content. After summarise pass it on to insight researcher\n",
    "#             to provide insights for each topic\"\"\")]\n",
    "# }):\n",
    "#     if \"__end__\" not in s:\n",
    "#         print(s)\n",
    "#         print(\"----\")\n",
    "# \n",
    "final_response = graph.invoke({\n",
    "    \"messages\": [HumanMessage(\n",
    "        content=\"\"\"Search for the latest AI technology trends in 2024,\n",
    "                summarize the content\n",
    "                and provide insights for each topic.\"\"\")]\n",
    "})\n",
    "\n",
    "print(final_response['messages'][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "id": "3d984065f58958a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
